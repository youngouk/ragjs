# ë¬¸ì„œ ì²˜ë¦¬ ë° ì €ì¥ ê³¼ì • ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” Simple RAG ì‹œìŠ¤í…œì—ì„œ ë¬¸ì„œê°€ ì—…ë¡œë“œëœ í›„ ì–´ë–»ê²Œ ì²˜ë¦¬ë˜ì–´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ëŠ”ì§€ë¥¼ ì´ˆë³´ ê°œë°œìê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ”„ ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì „ì²´ íë¦„

```
íŒŒì¼ ì—…ë¡œë“œ â†’ í˜•ì‹ ê²€ì¦ â†’ í…ìŠ¤íŠ¸ ì¶”ì¶œ â†’ ì²­í¬ ë¶„í•  â†’ ì„ë² ë”© ìƒì„± â†’ ë²¡í„° DB ì €ì¥
```

## ğŸ“ ì§€ì› íŒŒì¼ í˜•ì‹

### í˜„ì¬ ì§€ì› í˜•ì‹
- **PDF** (.pdf) - Adobe PDF ë¬¸ì„œ
- **DOCX** (.docx) - Microsoft Word ë¬¸ì„œ  
- **TXT** (.txt) - ì¼ë°˜ í…ìŠ¤íŠ¸ íŒŒì¼
- **XLSX** (.xlsx) - Microsoft Excel ìŠ¤í”„ë ˆë“œì‹œíŠ¸
- **CSV** (.csv) - ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê°’ íŒŒì¼

### íŒŒì¼ ì œí•œì‚¬í•­
- **ìµœëŒ€ íŒŒì¼ í¬ê¸°**: 100MB
- **í•œ ë²ˆì— ì—…ë¡œë“œ**: 1ê°œ íŒŒì¼
- **í—ˆìš© ë¬¸ì ì¸ì½”ë”©**: UTF-8

## ğŸš€ ë‹¨ê³„ë³„ ë¬¸ì„œ ì²˜ë¦¬ ê³¼ì •

### 1ë‹¨ê³„: íŒŒì¼ ì—…ë¡œë“œ ë° ì´ˆê¸° ê²€ì¦
**ìœ„ì¹˜**: `src/routes/upload.ts` - POST `/api/upload`

#### 1-1. ë©€í„°(Multer) íŒŒì¼ ì²˜ë¦¬
```typescript
const storage = multer.diskStorage({
  destination: async (req, file, cb) => {
    // uploads/ í´ë”ì— íŒŒì¼ ì €ì¥
    await fs.mkdir(config.upload.upload_dir, { recursive: true });
    cb(null, config.upload.upload_dir);
  },
  filename: (req, file, cb) => {
    // ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ UUID ì¶”ê°€
    const ext = path.extname(file.originalname);
    const basename = path.basename(file.originalname, ext);
    const filename = `${basename}_${generateUUID()}${ext}`;
    cb(null, filename);
  }
});
```

**ì²˜ë¦¬ ë‚´ìš©**:
- íŒŒì¼ì„ `uploads/` í´ë”ì— ì €ì¥
- íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ UUID ì¶”ê°€
- ì˜ˆì‹œ: `ê³„ì•½ì„œ.pdf` â†’ `ê³„ì•½ì„œ_abc123-def456-789.pdf`

#### 1-2. íŒŒì¼ í˜•ì‹ ë° í¬ê¸° ê²€ì¦
```typescript
const fileFilter = (req, file, cb) => {
  const ext = path.extname(file.originalname).toLowerCase().slice(1);
  
  if (config.upload.allowed_types.includes(ext)) {
    cb(null, true);  // í—ˆìš©ëœ íŒŒì¼ í˜•ì‹
  } else {
    const error = new Error(`File type .${ext} is not allowed`);
    cb(error);  // ê±°ë¶€
  }
};

const upload = multer({
  storage,
  fileFilter,
  limits: {
    fileSize: config.upload.max_file_size,  // 100MB ì œí•œ
    files: 1  // í•œ ë²ˆì— 1ê°œ íŒŒì¼
  }
});
```

### 2ë‹¨ê³„: ë°±ê·¸ë¼ìš´ë“œ ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œì‘
**ìœ„ì¹˜**: `src/routes/upload.ts` - `processFileAsync()` í•¨ìˆ˜

```typescript
// ì‘ì—… ID ìƒì„± ë° ì´ˆê¸° ìƒíƒœ ì„¤ì •
const jobId = generateUUID();
const job = {
  id: jobId,
  filename: req.file.originalname,
  status: 'processing',
  progress: 0,
  created_at: new Date().toISOString()
};

// ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬ ì‹œì‘
processFileAsync(jobId, req.file);

// ì¦‰ì‹œ ì‘ë‹µ ë°˜í™˜ (non-blocking)
res.success({
  success: true,
  jobId,
  message: 'File uploaded successfully. Processing started.'
});
```

**ì‚¬ìš©ì ê²½í—˜**:
- ì‚¬ìš©ìëŠ” íŒŒì¼ ì—…ë¡œë“œ í›„ ì¦‰ì‹œ ì‘ë‹µ ë°›ìŒ
- `jobId`ë¡œ ì²˜ë¦¬ ìƒíƒœë¥¼ ì¶”í›„ í™•ì¸ ê°€ëŠ¥

### 3ë‹¨ê³„: DocumentProcessorë¥¼ í†µí•œ ë¬¸ì„œ ì²˜ë¦¬
**ìœ„ì¹˜**: `src/services/DocumentProcessor.ts` - `processDocument()` ë©”ì„œë“œ

#### 3-1. íŒŒì¼ ì •ë³´ ìˆ˜ì§‘ ë° ê²€ì¦
```typescript
// íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ë° í¬ê¸° í™•ì¸
await fs.access(filePath);
const fileStats = await fs.stat(filePath);

// íŒŒì¼ í¬ê¸° ì œí•œ ì¬í™•ì¸ (100MB)
if (fileStats.size > maxFileSize) {
  throw new Error(`File too large: ${Math.round(fileStats.size / 1024 / 1024)}MB`);
}

// ë©”íƒ€ë°ì´í„° ìƒì„±
const metadata = {
  filename,
  file_type: fileExt,
  file_size: fileStats.size,
  upload_date: fileStats.birthtime.toISOString(),
  processing_date: new Date().toISOString()
};
```

#### 3-2. íŒŒì¼ í˜•ì‹ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ

**PDF ì²˜ë¦¬** (`processPDF()`)
```typescript
const dataBuffer = await fs.readFile(filePath);
const pdfData = await pdfParse(dataBuffer);

// ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
const metadata = {
  total_pages: pdfData.numpages,
  title: pdfData.info?.Title,
  author: pdfData.info?.Author,
  subject: pdfData.info?.Subject
};

return {
  text: pdfData.text,  // ì¶”ì¶œëœ í…ìŠ¤íŠ¸
  metadata
};
```

**DOCX ì²˜ë¦¬** (`processDOCX()`)
```typescript
const dataBuffer = await fs.readFile(filePath);
const result = await mammoth.extractRawText({ buffer: dataBuffer });

return {
  text: result.value,  // ì¶”ì¶œëœ í…ìŠ¤íŠ¸
  metadata: {}
};
```

**TXT ì²˜ë¦¬** (`processTXT()`)
```typescript
return await fs.readFile(filePath, 'utf-8');
```

**XLSX ì²˜ë¦¬** (`processXLSX()`)
```typescript
const workbook = XLSX.readFile(filePath);
const textContent = [];

workbook.SheetNames.forEach((sheetName) => {
  const worksheet = workbook.Sheets[sheetName];
  const csvString = XLSX.utils.sheet_to_csv(worksheet);
  textContent.push(`Sheet: ${sheetName}\n${csvString}\n`);
});

return textContent.join('\n');
```

**CSV ì²˜ë¦¬** (`processCSV()`)
```typescript
const fileContent = await fs.readFile(filePath, 'utf-8');
const results = [];

// CSVë¥¼ íŒŒì‹±í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
stream
  .pipe(csv())
  .on('data', (row) => {
    const rowText = Object.entries(row)
      .map(([key, value]) => `${key}: ${value}`)
      .join(', ');
    results.push(rowText);
  })
  .on('end', () => {
    resolve(results.join('\n'));
  });
```

### 4ë‹¨ê³„: í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
**ìœ„ì¹˜**: `src/services/DocumentProcessor.ts` - `splitTextIntoChunks()` ë©”ì„œë“œ

#### 4-1. ì²­í¬ ë¶„í•  ì „ëµ
```typescript
const defaultChunkSize = 1000;  // 1000ì
const defaultOverlap = 200;     // 200ì ì˜¤ë²„ë©
```

**ì˜¤ë²„ë©ì´ ì¤‘ìš”í•œ ì´ìœ **:
- ë¬¸ì¥ì´ë‚˜ ë‹¨ë½ì´ ì²­í¬ ê²½ê³„ì—ì„œ ì˜ë¦¬ëŠ” ê²ƒì„ ë°©ì§€
- ì—°ì†ì„± ìˆëŠ” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
- ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ

#### 4-2. ì§€ëŠ¥ì  ì²­í¬ ë¶„í• 
```typescript
function splitTextIntoChunks(text, chunkSize, overlap) {
  const chunks = [];
  let start = 0;

  while (start < text.length) {
    let end = Math.min(start + chunkSize, text.length);
    
    // ë‹¨ì–´ ê²½ê³„ì—ì„œ ìë¥´ê¸° (ë§ˆì§€ë§‰ ì²­í¬ê°€ ì•„ë‹Œ ê²½ìš°)
    if (end < text.length) {
      const lastSpaceIndex = text.lastIndexOf(' ', end);
      const lastNewlineIndex = text.lastIndexOf('\n', end);
      const lastPeriodIndex = text.lastIndexOf('.', end);
      
      // ê°€ì¥ ì ì ˆí•œ ë¶„í•  ì§€ì  ì„ íƒ
      const bestCutPoint = Math.max(lastSpaceIndex, lastNewlineIndex, lastPeriodIndex);
      if (bestCutPoint > start + chunkSize * 0.5) {
        end = bestCutPoint + 1;
      }
    }

    const chunk = text.slice(start, end).trim();
    if (chunk.length > 0) {
      chunks.push(chunk);
    }

    // ì˜¤ë²„ë©ì„ ê³ ë ¤í•œ ë‹¤ìŒ ì‹œì‘ì  ê³„ì‚°
    start = Math.max(start + chunkSize - overlap, end);
  }

  return chunks;
}
```

**ì²­í¬ ë¶„í•  ì˜ˆì‹œ**:
```
ì›ë³¸ í…ìŠ¤íŠ¸: "ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ê¹€ì² ìˆ˜ì…ë‹ˆë‹¤. íšŒì‚¬ì—ì„œ ê°œë°œìë¡œ ì¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì·¨ë¯¸ëŠ” ë…ì„œì…ë‹ˆë‹¤."

ì²­í¬ 1: "ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ê¹€ì² ìˆ˜ì…ë‹ˆë‹¤. íšŒì‚¬ì—ì„œ ê°œë°œìë¡œ"
ì²­í¬ 2: "ê°œë°œìë¡œ ì¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì·¨ë¯¸ëŠ” ë…ì„œì…ë‹ˆë‹¤."
       ^^^^^^^^ (ì˜¤ë²„ë© ë¶€ë¶„)
```

#### 4-3. DocumentChunk ê°ì²´ ìƒì„±
```typescript
const documentChunks = chunks.map((chunk, index) => ({
  id: this.generateChunkId(documentId, index),  // "doc_abc123_chunk_001"
  content: chunk,
  metadata: {
    source: filename,
    chunk_index: index,
    chunk_size: chunk.length,
    document_id: documentId,
    created_at: new Date().toISOString(),
    file_type: fileExt,
    // ... ê¸°íƒ€ ë©”íƒ€ë°ì´í„°
  }
}));
```

### 5ë‹¨ê³„: ì„ë² ë”© ìƒì„± (Dense Vector)
**ìœ„ì¹˜**: `src/services/EmbeddingService.ts`

#### 5-1. Google Geminië¥¼ í†µí•œ ì„ë² ë”© ìƒì„±
```typescript
async createEmbedding(text: string) {
  // í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ í™•ì¸ (10,000ì)
  if (text.length > 10000) {
    throw new Error('Text too long for embedding');
  }

  // Google Generative AI ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
  const embeddingModel = this.genAI.getGenerativeModel({ 
    model: 'embedding-001' 
  });
  
  const result = await embeddingModel.embedContent(text);
  const embedding = result.embedding.values;  // 768ì°¨ì› ë²¡í„°

  return {
    embedding,           // [0.1, 0.3, -0.2, ..., 0.5]
    model: 'embedding-001',
    tokens_used: Math.ceil(text.length / 4)  // ëŒ€ëµì  í† í° ê³„ì‚°
  };
}
```

#### 5-2. ë°°ì¹˜ ì„ë² ë”© ì²˜ë¦¬
```typescript
async createEmbeddingBatch(texts: string[]) {
  const batchSize = 5;  // ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ
  const batches = [];
  
  // í…ìŠ¤íŠ¸ë“¤ì„ 5ê°œì”© ë¬¶ì–´ì„œ ì²˜ë¦¬
  for (let i = 0; i < texts.length; i += batchSize) {
    batches.push(texts.slice(i, i + batchSize));
  }

  const embeddings = [];
  for (const batch of batches) {
    const batchPromises = batch.map(text => this.createEmbedding(text));
    const batchResults = await Promise.all(batchPromises);
    embeddings.push(...batchResults);
  }

  return {
    embeddings,
    total_tokens: embeddings.reduce((sum, emb) => sum + emb.tokens_used, 0),
    processing_time: Date.now() - startTime
  };
}
```

### 6ë‹¨ê³„: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
**ìœ„ì¹˜**: `src/services/VectorService.ts` - `addDocuments()` ë©”ì„œë“œ

#### 6-1. Qdrant ì»¬ë ‰ì…˜ í™•ì¸ ë° ìƒì„±
```typescript
async ensureCollection() {
  const collections = await this.client.getCollections();
  const collectionExists = collections.collections.some(
    col => col.name === this.collectionName
  );

  if (!collectionExists) {
    // ì»¬ë ‰ì…˜ ìƒì„±
    await this.client.createCollection(this.collectionName, {
      vectors: {
        size: 768,        // Gemini embedding ì°¨ì›
        distance: 'Cosine' // ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì‚¬ìš©
      },
      optimizers_config: {
        default_segment_number: 2
      },
      replication_factor: 1
    });
  }
}
```

#### 6-2. ë¬¸ì„œ ì²­í¬ë“¤ì„ Qdrantì— ì €ì¥
```typescript
async addDocuments(chunks: DocumentChunk[]) {
  const batchSize = 100;  // í•œ ë²ˆì— 100ê°œì”© ì²˜ë¦¬
  
  for (let i = 0; i < chunks.length; i += batchSize) {
    const batch = chunks.slice(i, i + batchSize);
    
    // ë°°ì¹˜ì— ëŒ€í•´ ì„ë² ë”© ìƒì„±
    const texts = batch.map(chunk => chunk.content);
    const embeddingResult = await embeddingService.createEmbeddingBatch(texts);

    // Qdrant í¬ì¸íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    const points = batch.map((chunk, index) => ({
      id: chunk.id,                                    // "doc_abc123_chunk_001"
      vector: embeddingResult.embeddings[index].embedding,  // [0.1, 0.3, ...]
      payload: {
        content: chunk.content,                        // ì›ë³¸ í…ìŠ¤íŠ¸
        source: chunk.metadata.source,                 // íŒŒì¼ëª…
        chunk_index: chunk.metadata.chunk_index,       // ì²­í¬ ì¸ë±ìŠ¤
        document_id: chunk.metadata.document_id,       // ë¬¸ì„œ ID
        file_type: chunk.metadata.file_type,          // íŒŒì¼ í˜•ì‹
        created_at: chunk.metadata.created_at,         // ìƒì„± ì‹œê°„
        // ... ê¸°íƒ€ ë©”íƒ€ë°ì´í„°
      }
    }));

    // Qdrantì— í¬ì¸íŠ¸ë“¤ ì €ì¥
    await this.client.upsert(this.collectionName, {
      wait: true,
      points
    });
  }
}
```

## ğŸ“Š ì²˜ë¦¬ ìƒíƒœ ì¶”ì 

### ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
```typescript
async function processFileAsync(jobId, file) {
  const job = processingJobs.get(jobId);
  
  job.progress = 10;  // ì²˜ë¦¬ ì‹œì‘
  job.progress = 20;  // í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ
  job.progress = 50;  // ì²­í¬ ë¶„í•  ì™„ë£Œ  
  job.progress = 80;  // ì„ë² ë”© ìƒì„± ì™„ë£Œ
  job.progress = 100; // ë²¡í„° DB ì €ì¥ ì™„ë£Œ
}
```

### ìƒíƒœ ë©”ì‹œì§€
```typescript
function getStatusMessage(job) {
  switch (job.status) {
    case 'processing':
      if (job.progress < 30) return 'Parsing document content...';
      if (job.progress < 50) return 'Splitting text into chunks...';
      if (job.progress < 70) return 'Generating embeddings...';
      if (job.progress < 90) return 'Storing in vector database...';
      return 'Finalizing processing...';
    case 'completed':
      return `Successfully processed into ${job.chunks_created} chunks`;
    case 'failed':
      return job.error || 'Processing failed';
  }
}
```

## ğŸ¯ ì²˜ë¦¬ ê²°ê³¼ ì˜ˆì‹œ

### ì„±ê³µì ì¸ ì²˜ë¦¬ ê²°ê³¼
```json
{
  "success": true,
  "document_id": "doc_abc123",
  "filename": "ê³„ì•½ì„œ.pdf",
  "file_type": "pdf",
  "total_chunks": 23,
  "processing_time": 15420,
  "chunks_created": [
    {
      "id": "doc_abc123_chunk_000",
      "content": "ë³¸ ê³„ì•½ì„œëŠ” ê°‘ê³¼ ì„ ì‚¬ì´ì˜ ì„œë¹„ìŠ¤ ì œê³µ ê³„ì•½ì— ê´€í•œ ë‚´ìš©ì„...",
      "metadata": {
        "source": "ê³„ì•½ì„œ.pdf",
        "chunk_index": 0,
        "document_id": "doc_abc123",
        "file_type": "pdf"
      }
    }
    // ... ë” ë§ì€ ì²­í¬ë“¤
  ]
}
```

### ì²˜ë¦¬ ì‹œê°„ ë¶„ì„ (ì˜ˆì‹œ)
- **í…ìŠ¤íŠ¸ ì¶”ì¶œ**: 500-2000ms (íŒŒì¼ í¬ê¸°ì— ë”°ë¼)
- **ì²­í¬ ë¶„í• **: 50-200ms  
- **ì„ë² ë”© ìƒì„±**: 3000-8000ms (ì²­í¬ ìˆ˜ì— ë”°ë¼)
- **ë²¡í„° DB ì €ì¥**: 1000-3000ms

**ì´ ì²˜ë¦¬ ì‹œê°„**: 5-15ì´ˆ (ë¬¸ì„œ í¬ê¸°ì™€ ë³µì¡ë„ì— ë”°ë¼)

## ğŸ”§ ì„ì‹œ íŒŒì¼ ì •ë¦¬

### ì„±ê³µ ì‹œ ì •ë¦¬
```typescript
if (processingResult.success) {
  // ì²˜ë¦¬ ì™„ë£Œ í›„ ì„ì‹œ íŒŒì¼ ì‚­ì œ
  await documentProcessor.cleanupTempFile(file.path);
}
```

### ì‹¤íŒ¨ ì‹œ ì •ë¦¬
```typescript
catch (error) {
  // ì‹¤íŒ¨ ì‹œì—ë„ ì„ì‹œ íŒŒì¼ ì •ë¦¬
  try {
    await documentProcessor.cleanupTempFile(file.path);
  } catch (cleanupError) {
    logger.warn('Failed to cleanup file after processing failure');
  }
}
```

ì´ ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë¬¸ì„œê°€ ê²€ìƒ‰ ê°€ëŠ¥í•œ ë²¡í„° í˜•íƒœë¡œ ë³€í™˜ë˜ì–´ RAG ì‹œìŠ¤í…œì—ì„œ í™œìš©ë©ë‹ˆë‹¤.